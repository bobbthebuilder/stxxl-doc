\documentclass[twoside]{book}
%\usepackage{algorithmic}
%\usepackage{eepic}
%\usepackage{epic}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{latexsym}
\usepackage{times}
\usepackage{mathptm}
\usepackage{bbold}
\usepackage{comment}
\usepackage{epsfig}
%\usepackage{fancyheadings}
\usepackage{fancyhdr}
\usepackage{float}
%Floatflt was apparently removed for licencing problems. 
%http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=565457
%\usepackage{floatflt} 
\usepackage{graphics}
\usepackage{moreverb}
\usepackage{epic}
\usepackage{eepic}
\usepackage{theorem}
\usepackage{url}
%\usepackage{html}
\usepackage{listings}
\usepackage{graphicx}

\hoffset=-1in
\voffset=-1in
%-- Textbreite
\setlength{\textwidth}{120mm}           % 9/12 * 160mm
\setlength{\oddsidemargin}{23.3mm}      % 1/12 * 160mm + 10 ungesehene
\setlength{\evensidemargin}{26.6mm}     % 2/12 * 160mm
%-- Texthoehe
%\setlength{\textheight}{180mm}          % 9/12 * 240mm
\setlength{\textheight}{220mm}          % 9/12 * 240mm
\setlength{\topmargin}{20mm}            % 1/12 * 240mm


\addtolength{\textheight}{-\headheight}
\addtolength{\textheight}{-\headsep}

\hfuzz 1.5pt
\renewcommand{\topfraction}{0.999}
\renewcommand{\bottomfraction}{0.999}
\renewcommand{\textfraction}{0.001}


\pagestyle{fancyplain}

\renewcommand{\chaptermark}[1]{\markboth{#1}{#1}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\lhead[\fancyplain{{\tiny Dementiev \today} \bf\thepage}{\bf\thepage}]{
\fancyplain{\rightmark}}
\rhead[\fancyplain{}{\leftmark}]{\fancyplain{{\tiny Dementiev \today}
\bf\thepage}{\bf\thepage}} 
\cfoot[{\fancyplain{}{}}]{\fancyplain{}{}}

\renewcommand{\labelenumi}{\alph{enumi})}

\include{allmakros}

\makeindex

%\newcommand{\stxxl}{{S{\small TXXL} }}
%\newcommand{\stxxll}{S{\fontsize{11pt}{11pt}\selectfont TXXL} }
\newcommand{\stxxl}{{\sc Stxxl} }

\begin{document}
\lstset{language=C++,frame=single,tabsize=4,basicstyle=\ttfamily\small,
        moredelim=[is][\underbar]{@}{@}}

\pagenumbering{roman}%
% \pagestyle{empty}
\setcounter{page}{-2}%
\begin{titlepage}%
under development
\large
\vspace*{1cm}
\vspace*{1cm}
\vspace*{1cm}
\begin{center}
{\huge \stxxl Tutorial}\\

for \stxxl 1.1

\vspace{3mm}

{\LARGE Roman Dementiev\\[2mm]}

\vspace*{\fill}

{\normalsize under development}
\end{center}
\thispagestyle{empty}
\end{titlepage}


\thispagestyle{empty}

%\chapter*{Foreword}

\setcounter{tocdepth}{1}
\tableofcontents
\clearpage
\pagenumbering{arabic}
% \pagestyle{empty}
\setcounter{page}{1}


\chapter{Introduction}

There exist many application that have to process data sets which
can not fit into the main memory of a computer, but external memory
(e.g.\ hard disks). The examples are Geographic Information
Systems, Internet and telecommunication billing
systems, Information Retrieval systems
manipulating terabytes of data. 

The most of engineering efforts have been spent on designing
algorithms which work on data that \emph{completely} resides in the main
memory. The algorithms assume that the execution time of any
memory access is a \emph{small} constant (1--20 ns). But it is no more
true when 
an application needs to access external memory (EM). Because of the
mechanical nature of the position seeking routine, a random hard disk
access takes about 3--20 ms. This 
is about {\bf 1~000~000} longer than a main memory access. Since the I/Os
are apparently the major bottleneck of applications that handle large
data sets, they minimize the number of performed I/Os.
A new measure of program performance is becoming sound -- the I/O
complexity. 

Vitter and Shriver \cite{VitShr94both} came up with a model for designing I/O
efficient algorithms. In order to amortize the high cost of a random
disk access\footnote{Modern disks after locating the position of the
data on the surface can deliver the contiguous data blocks at speed
50-60 MiB/s. For example with the seek time 10~ms, 1~MiB can be read or
written in $10~+~1000~\times~1/50~=~30$~ms, 1~byte -- in 10.02~ms.},
external data loaded in contiguous chunks of size $B$. To increase
bandwidth external memory algorithms use multiple parallel disks. The
algorithms try in each I/O step transfer $D$ blocks between the main
memory and disks (one block per each disk).


I/O efficient algorithms have been developed for many
problem domains, including fundamental ones like sorting \cite{},
graph algorithms \cite{}, string processing \cite{}, computational
geometry \cite{}. 

However there is the ever increasing gap between theoretical
nouveau of external memory algorithms and their use in practice.   
Several EM software library projects (LEDA-SM \cite{CraMeh99} and TPIE
\cite{APV02}) attempted to 
reduce this gap. They offer frameworks which aim to speed up the
process of implementing I/O efficient algorithms giving a high level
abstraction away the details of how I/O is performed. Implementations
of many EM algorithms and data structures are offered as well.

Those projects are excellent proofs of EM paradigm, but have
some drawbacks which \emph{impede} their practical use.

Therefore we started to develop \stxxl library, which tries to avoid
those obstacles. The objectives of \stxxl project (distinguishing
it from other libraries): 
\begin{itemize}
\item Make the library able to handle problems of \emph{real world size}
(up to dozens of terabytes). 

\item Offer \emph{transparent} support of parallel disks. This feature
although announced has not been implemented in any library.
\item Implement \emph{parallel} disk algorithms. LEDA-SM and TPIE
libraries offer only implementations of single disk EM algorithms.
\item Use computer resources more efficiently. \stxxl allows 
transparent \emph{overlapping} of I/O and computation in many algorithms and
data structures.
\item Care about constant factors in I/O volume. A unique library
feature \emph{``pipelining''} can \emph{half} the number of I/Os
performed by an algorithm.
\item Care about the \emph{internal work}, improve the in-memory
algorithms. Having many disks can hide the latency and increase the
I/O bandwidth, s.t. internal work becomes a bottleneck.
\item Care about operating system overheads. Use \emph{unbuffered disk
access} to avoid superfluous copying of data.
\item Shorten \emph{development times} providing well known interface for EM
algorithms and data structures. We provide STL-compatible\footnote{STL
-- Standard Template Library \cite{stepanov94standard} is freely available library of
algorithms and data structures delivered with almost any C++
compiler.} interfaces for our implementations.
\end{itemize}

\chapter{Prerequisites}

The intended audience of this tutorial are developers or researchers who
develop applications or implement algorithms processing large data sets
which do not fit into the main memory of a computer. They must have
basic knowledge in the theory of external memory computing and 
have working knowledge of C++ and an experience with programming using
STL. Familiarity with key concepts of generic programming and
C++ template mechanism is assumed.


\chapter{Installation}

See the \stxxl home page \url{stxxl.sourceforge.net} for the installation
instruction for your compiler and operating system.


\chapter{A Starting Example}
% A billing system for phone calls
% AT&T Gecko 60G records, 2.6 TB

Let us start with a toy but pretty relevant problem: the phone
call billing problem. You are given a sequence of event
records. Each record has a time stamp (time when the event had
happened), type of event ('call begin' or 'call end'), the callers
number, and the destination number. The event sequence is
time-ordered. Your task is to generate a bill for each subscriber
that includes cost of all her calls. The solution is uncomplicated:
sort the records by the callers number. Since the sort brings all records
of a subscriber together, we \emph{scan} the sorted result computing
and summing up the costs of all calls of a particular subscriber.
The phone companies record up to 300 million transactions per
day. AT\&T billing system Gecko \cite{BillingLarge} has to 
process databases with about 60 billion records, occupying 2.6
terabytes. Certainly this volume can not be sorted in the main memory
of a single computer\footnote{Except may be in the main memory of an
expensive \emph{super}computer.}. 
Therefore we need to sort those huge data sets out-of-memory. Now
we show how \stxxl can be useful here, since it can handle large
volumes I/O efficiently. 

\section{STL Code}
If you are familiar with STL your the {\tt main} function of bill
generation program will probably look like this:

\begin{lstlisting}
int main(int argc, char * argv[])
{
  if(argc < 4) // check if all parameters are given 
  {            // in the command line
          print_usage(argv[0]);
          return 0;
  }
  // open file with the event log
  std::fstream in(argv[1],std::ios::in);
  // create a vector of log entries to read in
  std::vector<LogEntry> v;
  // read the input file and push the records
  // into the vector
  std::copy(std::istream_iterator<LogEntry>(in),
            std::istream_iterator<LogEntry>(),
            std::back_inserter(v));
  // sort records by callers number
  std::sort(v.begin(),v.end(),SortByCaller());
  // open bill file for output
  std::fstream out(argv[3],std::ios::out);
  // scan the vector and output bills
  std::for_each(v.begin(),v.end(),ProduceBill(out));
  return 0;
}
\end{lstlisting}

To complete the code we need to define the log entry data type 
{\tt LogEntry}, input operator {\tt >>} for {\tt LogEntry}, comparison
functor {\tt SortByCaller}, unary functor {\tt ProduceBills} used
for computing bills, and the {\tt print\_usage} function. 

\begin{lstlisting}
#include <algorithm> // for STL std::sort
#include <vector>    // for STL std::vector
#include <fstream>   // for std::fstream
#include <limits>
#include <ctime>     // for time_t type
#define CT_PER_MIN 2 // subscribers pay 2 cent per minute

struct LogEntry // the event log data structure
{
  long long int from; // callers number (64 bit integer)
  long long int to;   // destination number (64 bit int)
  time_t timestamp;   // time of event
  int event;          // event type 1 - call started
                      //            2 - call ended
};

// input operator used for reading from the file
std::istream & operator >> (std::istream & i, 
                            LogEntry & entry)
{
  i >> entry.from;
  i >> entry.to;
  i >> entry.timestamp;
  i >> entry.event;
  return i;
}






struct SortByCaller // comparison function
{
  bool operator() (     const LogEntry & a, 
                        const LogEntry & b) const
  {
        return  a.from < b.from ||
        (a.from == b.from && a.timestamp < b.timestamp) ||
        (a.from == b.from && a.timestamp == b.timestamp && 
            a.event < b.event);
  }
  static LogEntry min_value()
  { 
	LogEntry dummy;
	dummy.from = (std::numeric_limits<long long int>::min)();
	return dummy;
  }
  static LogEntry max_value()
  { 
	LogEntry dummy;
	dummy.from = (std::numeric_limits<long long int>::max)();
	return dummy;
  }
  
}

// unary function used for producing the bills
struct ProduceBill
{
        std::ostream & out; // stream for outputting 
                            // the bills
        unsigned sum;       // current subscribers debit
        LogEntry last;      // the last record 
        
        ProduceBill(std::ostream & o_):out(o_),sum(0)
        { 
                last.from = -1; 
        }
        
        void operator () (const LogEntry & e)
        {
                if(last.from == e.from)
                {
                    // either the last event was 'call started' 
                    // and current event is 'call ended' or the 
                    // last event was 'call ended' and current 
                    // event is 'call started'
                    assert( (last.event == 1 && e.event == 2) || 
                            (last.event == 2 && e.event == 1));     
                        
                    if(e.event == 2) // call ended
                            sum += CT_PER_MIN*
                            (e.timestamp - last.timestamp)/60;
                }
                else if(last.from != -1)
                {
                   // must be 'call ended'
                   assert(last.event == 2);
                   // must be 'call started'
                   assert(e.event == 1);
                        
                   // output the total sum
                   out << last.from <<"; "<< (sum/100)<<" EUR "
                             << (sum%100)<< " ct"<< std::endl;
                        
                   sum = 0; // reset the sum
                }
                        
                last = e;
        }
};


void print_usage(const char * program)
{
          std::cout << "Usage: "<<program<<
                " logfile main billfile" << std::endl;
          std::cout <<" logfile  - file name of the input"
                << std::endl;
          std::cout <<" main     - memory to use (in MiB)"
                << std::endl;
          std::cout <<" billfile - file name of the output"
                << std::endl;
}

\end{lstlisting}

measure the running time for in-core and out-of-core case,
point the I/O inefficiency of the code

\section{Going Large -- Use \stxxl}
In order to make the program I/O efficient we will replace the STL
internal memory data structures and algorithms by their \stxxl
counterparts. The changes are underlined.

\begin{lstlisting}
@#include <stxxl.h>@
// the rest of the code remains the same
int main(int argc, char * argv[])
{
  if(argc < 4) // check if all parameters are given 
  {            // in the command line
          print_usage(argv[0]);
          return 0;
  }
  // open file with the event log
  std::fstream in(argv[1],std::ios::in);
  // create a vector of log entries to read in
  @stxxl@::vector<LogEntry> v;
  // read the input file and push the records
  // into the vector
  std::copy(std::istream_iterator<LogEntry>(in),
            std::istream_iterator<LogEntry>(),
            std::back_inserter(v));
  // bound the main memory consumption by M 
  // during sorting
  const unsigned M = atol(argv[2])*1024*1024;
  // sort records by callers number
  @stxxl@::sort(v.begin(),v.end(),SortByCaller()@,M@);
  // open bill file for output
  std::fstream out(argv[3],std::ios::out);
  // scan the vector and output bills
  // the last parameter tells how many buffers 
  // to use for overlapping I/O and computation
  @stxxl@::for_each(v.begin(),v.end(),ProduceBill(out)@,2@);
  return 0;
}
\end{lstlisting}

As you note the changes are minimal. Only the namespaces and some
memory specific parameters had to be changed.

To compile the \stxxl billing program you may use the following {\tt
Makefile}: 


\begin{verbatim}
all: phonebills
# path to stxxl.mk file
# from your stxxl installation
include ~/stxxl/stxxl.mk

phonebills: phonebills.cpp
        $(STXXL_CXX) -c phonebills.cpp $(STXXL_CPPFLAGS)
        $(STXXL_CXX) phonebills.o -o phonebills.bin $(STXXL_LDLIBS)
clean:
        rm -f phonebills.bin phonebills.o
\end{verbatim}


Do not forget to configure you external memory space in file {\tt
.stxxl}. You can copy the {\tt config\_example} (Windows: {\tt config\_example\_win}) from the \stxxl
installation directory, and adapt it to your configuration.

% The sources of the billing program as well as input log generation
% program are available from \ldots.


% running times


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Pipelined/Stream Interfaces}


%data flow graph, file, sorting, streaming nodes\\
%compare with TPIE AMI\_scan


\section{Preliminaries}
\section{Node Interface}
\section{Scheduling}
\section{File Nodes -- {\tt streamify} and {\tt materialize}}
\section{Streaming Nodes}
\section{Sorting Nodes}
\label{pipesorting}
\subsection{Runs Creator -- {\tt stxxl::stream::runs\_creator}}
\subsection{Specializations of {\tt stxxl::stream::runs\_creator}}
\subsection{Runs Merger --  {\tt stxxl::stream::runs\_merger}}
\subsection{A Combination: {\tt stxxl::stream::sort}}

\section{A Pipelined Version of the Billing Application}

\begin{lstlisting}

\end{lstlisting}

\chapter{Internals}
\section{Block Management Layer}

\subsection{\texttt{stxxl::prefetch\_pool}}
\label{prefetchpoolsection}
\subsection{\texttt{stxxl::write\_pool}}
\label{writepoolsection}

\section{I/O Primitives Layer}
\section{Utilities}


\chapter{Miscellaneous}
\section{\stxxl Compile Flags}

\bibliographystyle{plain} \bibliography{tutorial}

\end{document}
